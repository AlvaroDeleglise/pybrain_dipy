{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTI Deterministic Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local fibre tracking is an approach used to model white matter fibres by creating streamlines from local directional information. The idea is as follows: if the local directionality of a tissue segment is known, one can integrate along those directions to build a complete representation of the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform local fibre tracking we needed:\n",
    "\n",
    "1) A method for estimating directions from a diffusion data set.\n",
    "\n",
    "2) A set of seeds from which to begin propagating streamlines\n",
    "\n",
    "3) A set of stopping criteria for streamline propagation\n",
    "\n",
    "4) A method for propagating streamlines.\n",
    "\n",
    "This example shows how to combine these parts to create a tractography reconstruction from a dMRI dataset using the DTI model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's load the Stanford's dMRI dataset (same dataset used on the previous tutorial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_fnames\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti\n",
    "\n",
    "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames('stanford_hardi')\n",
    "\n",
    "data, affine, hardi_img = load_nifti(hardi_fname, return_img=True)\n",
    "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the previous examples, the loaded data is masked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "maskdata, mask = median_otsu(data, vol_idx=range(0, 9),\n",
    "                             numpass=1, dilate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dipy also provides a file that labels white matter voxels of the Stanford's dMRI dataset by either 1 or 2. To speed the processing of this example, let's use these labels to only extract peaks in the labeled white matter voxels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.image import load_nifti_data\n",
    "\n",
    "label_fname = get_fnames('stanford_labels')\n",
    "\n",
    "labels = load_nifti_data(label_fname)\n",
    "\n",
    "white_matter = (labels == 1) | (labels == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Getting directions from the dMRI dataset\n",
    "\n",
    "In this example, we will use the DTI model to get the directions. For this we instantiate a Tensor model according to the data GradientTable object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.reconst.dti import TensorModel\n",
    "\n",
    "dti_model = TensorModel(gtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last tutorial we show that diffusion tensor main direction can be calculated from its eigenvectors. Here, DTI peaks are extracted using dipy's function \"peaks_from_model\". This function provides a more general strategy to extract directions that can be applied to different dMRI models. Below we extract directions on the white matter voxels (this step may take a couple of minutes to run).\n",
    "\n",
    "*Note: Function \"peaks_from_model\" requires a variable containing discrete directions for evaluation - this and other input parameters will be explained in more detail on following tutorials. For this example lets only load a default set of discrete directions available in dipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import default_sphere\n",
    "\n",
    "dti_peaks = peaks_from_model(dti_model, maskdata, default_sphere,\n",
    "                             relative_peak_threshold=.8,\n",
    "                             min_separation_angle=45,\n",
    "                             mask=white_matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quality assurance we can also visualize a slice from the direction field which we will use as the basis to perform the tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\anaconda3\\envs\\dipy_release\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dipy.viz import window, actor, has_fury\n",
    "\n",
    "if has_fury:\n",
    "    scene = window.Scene()\n",
    "    scene.add(actor.peak_slicer(dti_peaks.peak_dirs,\n",
    "                                dti_peaks.peak_values,\n",
    "                                colors=None))\n",
    "\n",
    "    window.record(scene, out_path='dti_direction_field.png', size=(900, 900))\n",
    "    window.show(scene, size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Defining the seeds where tracking will start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seeds for tracking are defined in Dipy using the function \"seeds_from_mask\" from \"dipy.tracking.utils\". For this example, we place a grid of 2 × 2 × 2 grid of seeds per voxel, in a sagittal slice of the corpus callosum. The voxels to seed are selected by the input \"seed_mask\" which here we use the regions with the label value 2 which corresponds to voxels in a sagittal slice of the corpus callosum. Tracking from this region will, therefore, give us a model of the corpus callosum tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "\n",
    "seed_mask = (labels == 2)\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine, density=[2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Defining the tracking stopping criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, streamlines are produced until reaching a voxels with FA lower than 0.2. For this, let's first compute the FA map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_fit = dti_model.fit(maskdata)\n",
    "fa = dti_fit.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Dipy, the stopping criterion area is defined using the function \"ThresholdStoppingCriterion\" from \"dipy.tracking.stopping_criterion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "\n",
    "stopping_criterion = ThresholdStoppingCriterion(fa, .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Propagating the streamlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the directions, starting position and stopping criterion defined we can start generating streamlines. In Dipy, the streamline generation has to be first initialized. For this, we use the function \"LocalTracking\" from \"dipy.tracking.local_tracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "\n",
    "streamlines_generator = LocalTracking(dti_peaks, stopping_criterion, seeds,\n",
    "                                      affine=affine, step_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamlines can then be generated using the \"Streamline\" function from dipy.tracking.streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.streamline import Streamlines\n",
    "\n",
    "# Generate streamlines object\n",
    "streamlines = Streamlines(streamlines_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we display the resulting streamlines using the fury python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.viz import colormap\n",
    "\n",
    "if has_fury:\n",
    "    # Prepare the display objects.\n",
    "    color = colormap.line_colors(streamlines)\n",
    "\n",
    "    streamlines_actor = actor.line(streamlines,\n",
    "                                   colormap.line_colors(streamlines))\n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(streamlines_actor)\n",
    "\n",
    "    # Save still images for this static example. Or for interactivity use\n",
    "    window.record(scene, out_path='dti_tractogram.png', size=(800, 800))\n",
    "    window.show(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve created a deterministic set of streamlines using the LocalTracking algorithm from the diffusion tensor main direction. This procedure is called deterministic because if you repeat the fiber tracking (keeping all the inputs the same) you will get exactly the same set of streamlines. We can save the streamlines as a Trackvis file so it can be loaded into other software for visualization or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "\n",
    "sft = StatefulTractogram(streamlines, hardi_img, Space.RASMM)\n",
    "save_trk(sft, \"dti_CC_tractography_deterministic.trk\", streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
